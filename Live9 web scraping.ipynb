{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Find if a number is prime or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "say n=13, check if all the nos upto 13 can divide n without a remainder, if it can divide it is a not a prime, else it is a prime\n",
    "\n",
    "if n is not divisible:\n",
    "    n is prime\n",
    "else:\n",
    "    n is not prime\n",
    "\n",
    "#pseudo code\n",
    "n = input a number(integer) (> 1)\n",
    "for i = 2 to n -1:\n",
    "    if n % i == 0:\n",
    "        not a prime\n",
    "        break\n",
    "else:\n",
    "    prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "not a prime number\n"
     ]
    }
   ],
   "source": [
    "num = int(input(\"Enter a number > 1\"))\n",
    "\n",
    "for i in range(2, num):\n",
    "    if num % i == 0:\n",
    "        print(\"not a prime number\")\n",
    "        break\n",
    "else:\n",
    "    print(\"prime number\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Get the frequencies of occurence of each element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Go to each element and count each number\n",
    "\n",
    "obj = {}\n",
    "for no in lst:\n",
    "    if no in obj:\n",
    "        obj[no] + 1\n",
    "    else:\n",
    "        obj[no] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{1: 2, 2: 2, 3: 2, 4: 2, 5: 3}\n"
     ]
    }
   ],
   "source": [
    "lst = [1,1,2,3,4,5,2,3,4,5, 5]\n",
    "d = {}\n",
    "\n",
    "for no in lst:\n",
    "    if no in d:\n",
    "        d[no] = d[no] + 1\n",
    "    else:\n",
    "        d[no] = 1\n",
    "\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Web Scraping\n",
    "BeautifulSoup is the best library for web Scraping\n",
    "Sample code: https://medium.freecodecamp.org/how-to-scrape-websites-with-python-and-beautifulsoup-5946935d93fe # bloomberg  website has changed currently \n",
    "\n",
    "Steps for web scraping:\n",
    "1. Obtain a page to get the source (html/js) can use urllib2 puthon library\n",
    "2. Pinpoint the data we want\n",
    "3. Understand the structure of the HTML using Inspect element to fetch the html element - we can use grep/beautifulsoup in python to search for the text using the html element\n",
    "4. Go to the part where we want to search the data we want \n",
    "5. Cut the data we want and store it\n",
    "\n",
    "Scraping can be done on static and dynamic websites\n",
    "\n",
    "Static means only HTML, no need to execute JS, urllib2 can do the job for static website\n",
    "\n",
    "Dynamic is HTML content and browser loads the JS o fill up the website with data\n",
    "We can use Selenium tool for dynamic web pages https://medium.freecodecamp.org/better-web-scraping-in-python-with-selenium-beautiful-soup-and-pandas-d6390592e251\n",
    "Selenium lets us open any browser of our choice present on our PC, helps us open urls and simulate button clicks\n",
    "Browser can internally execute JS code\n",
    "we can replace the urllib2 library instead of selenium\n",
    "\n",
    "Many webstes often change the DOM structure to avoid scraping. Lots of websites use random nos to store the dom structures\n",
    "\n",
    "Pay attention to the website policies for scraping, else there can be legal actions"
   ]
  }
 ]
}